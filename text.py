# -*- coding: utf-8 -*-
"""task

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18t3Mc_c0okxH6Rlyz-0F-vD2fhsR0OfL
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.utils.class_weight import compute_class_weight
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, GlobalMaxPooling1D, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.utils import to_categorical

# ================== Load data ==================
df = pd.read_csv("/content/New_CEFR_label.csv")

# Encode labels
le = LabelEncoder()
df["label"] = le.fit_transform(df["CEFR"])
num_classes = len(le.classes_)

# ================== Train / Validation / Test split ==================
X_train, X_temp, y_train, y_temp = train_test_split(
    df["Text"], df["label"], test_size=0.3, random_state=42, stratify=df["label"]
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
)

# ================== Tokenization ==================
max_words = 30000
max_len = 400
tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(X_train)

X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=max_len)
X_val_seq = pad_sequences(tokenizer.texts_to_sequences(X_val), maxlen=max_len)
X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_len)

# ================== One-hot encode labels ==================
y_train_cat = to_categorical(y_train, num_classes=num_classes)
y_val_cat = to_categorical(y_val, num_classes=num_classes)
y_test_cat = to_categorical(y_test, num_classes=num_classes)

# ================== Model ==================
model = Sequential([
    Embedding(max_words, 300, input_length=max_len),
    Bidirectional(LSTM(128, return_sequences=True)),
    GlobalMaxPooling1D(),
    BatchNormalization(),
    Dropout(0.5),
    Dense(64, activation="relu"),
    Dropout(0.4),
    Dense(num_classes, activation="softmax")
])

model.compile(
    loss="categorical_crossentropy",
    optimizer="adam",
    metrics=["accuracy"]
)

# ================== Callbacks ==================
callbacks = [
    EarlyStopping(monitor="val_loss", patience=3, restore_best_weights=True),
    ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=2)
]

# ================== Compute class weights ==================
class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y_train),
    y=y_train
)
class_weights_dict = {i: w for i, w in enumerate(class_weights)}
print("Class weights:", class_weights_dict)

# ================== Training ==================
history = model.fit(
    X_train_seq, y_train_cat,
    validation_data=(X_val_seq, y_val_cat),
    epochs=20,
    batch_size=8,
    callbacks=callbacks,
    class_weight=class_weights_dict,
    verbose=1
)

# ================== Final evaluation ==================
loss, acc = model.evaluate(X_test_seq, y_test_cat, verbose=0)
print(f"Test Accuracy: {acc:.4f}")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, GlobalMaxPooling1D, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.utils import to_categorical

# Load data
df = pd.read_csv("/content/New_CEFR_label.csv")

# Encode labels
le = LabelEncoder()
df["label"] = le.fit_transform(df["CEFR"])
num_classes = len(le.classes_)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    df["Text"], df["label"], test_size=0.2, random_state=42
)

# Tokenization
max_words = 30000
max_len = 400
tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(X_train)

X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=max_len)
X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_len)

# One-hot encode labels
y_train_cat = to_categorical(y_train, num_classes=num_classes)
y_test_cat = to_categorical(y_test, num_classes=num_classes)

# Model
model = Sequential([
    Embedding(max_words, 300, input_length=max_len),
    Bidirectional(LSTM(128, return_sequences=True)),
    GlobalMaxPooling1D(),
    BatchNormalization(),
    Dropout(0.5),
    Dense(64, activation="relu"),
    Dropout(0.4),
    Dense(num_classes, activation="softmax")
])

model.compile(
    loss="categorical_crossentropy",
    optimizer="adam",
    metrics=["accuracy"]
)

# Callbacks
callbacks = [
    EarlyStopping(monitor="val_accuracy", patience=3, restore_best_weights=True),
    ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=2)
]

# Training
history = model.fit(
    X_train_seq, y_train_cat,
    validation_data=(X_test_seq, y_test_cat),
    epochs=20,
    batch_size=8,
    callbacks=callbacks,
    verbose=1
)

# Evaluation
loss, acc = model.evaluate(X_test_seq, y_test_cat, verbose=0)
print(f"Validation Accuracy: {acc:.4f}")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import class_weight
from imblearn.over_sampling import RandomOverSampler
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, GlobalMaxPooling1D, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.utils import to_categorical
import tensorflow as tf
from sklearn.metrics import classification_report

# -----------------------
# Load Data
# -----------------------
df = pd.read_csv("/content/New_CEFR_label.csv")

# Encode labels
le = LabelEncoder()
df["label"] = le.fit_transform(df["CEFR"])
num_classes = len(le.classes_)

# Train/test split (stratify to maintain class distribution)
X_train, X_test, y_train, y_test = train_test_split(
    df["Text"], df["label"], test_size=0.2, random_state=42, stratify=df["label"]
)

# -----------------------
# Oversample minority classes
# -----------------------
ros = RandomOverSampler(random_state=42)
X_train_res, y_train_res = ros.fit_resample(np.array(X_train).reshape(-1,1), y_train)
X_train_res = X_train_res.ravel()

# -----------------------
# Tokenization
# -----------------------
max_words = 30000
max_len = 400
tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(X_train_res)

X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train_res), maxlen=max_len)
X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_len)

# One-hot encode labels
y_train_cat = to_categorical(y_train_res, num_classes=num_classes)
y_test_cat = to_categorical(y_test, num_classes=num_classes)

# -----------------------
# Class weights
# -----------------------
class_weights = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y_train_res),
    y=y_train_res
)
class_weights_dict = dict(enumerate(class_weights))

# -----------------------
# Focal loss
# -----------------------
def focal_loss(gamma=2., alpha=.25):
    def loss_fn(y_true, y_pred):
        y_true = tf.cast(y_true, tf.float32)
        ce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)
        pt = tf.exp(-ce)
        return alpha * tf.pow(1-pt, gamma) * ce
    return loss_fn

# -----------------------
# Build Model
# -----------------------
model = Sequential([
    Embedding(max_words, 300),
    Bidirectional(LSTM(64, return_sequences=True)),  # smaller LSTM to reduce overfitting
    GlobalMaxPooling1D(),
    BatchNormalization(),
    Dropout(0.5),
    Dense(64, activation="relu"),
    Dropout(0.4),
    Dense(num_classes, activation="softmax")
])

# Compile
model.compile(
    loss=focal_loss(gamma=2., alpha=0.25),
    optimizer="adam",
    metrics=["accuracy", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]
)

# -----------------------
# Callbacks
# -----------------------
callbacks = [
    EarlyStopping(monitor="val_loss", patience=3, restore_best_weights=True),
    ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=2)
]

# -----------------------
# Train
# -----------------------
history = model.fit(
    X_train_seq, y_train_cat,
    validation_data=(X_test_seq, y_test_cat),
    epochs=20,
    batch_size=8,
    callbacks=callbacks,
    class_weight=class_weights_dict,
    verbose=1
)

# -----------------------
# Evaluation
# -----------------------
y_pred = model.predict(X_test_seq)
y_pred_classes = np.argmax(y_pred, axis=1)

print("Classification Report:\n")
print(classification_report(y_test, y_pred_classes, target_names=le.classes_))

# Overall metrics
loss, acc, precision, recall = model.evaluate(X_test_seq, y_test_cat, verbose=0)
f1 = 2 * (precision * recall) / (precision + recall + 1e-8)

print(f"Validation Accuracy: {acc:.4f}")
print(f"Validation Precision: {precision:.4f}")
print(f"Validation Recall: {recall:.4f}")
print(f"Validation F1-Score: {f1:.4f}")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import class_weight
from imblearn.over_sampling import RandomOverSampler
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, GlobalMaxPooling1D, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.utils import to_categorical
import tensorflow as tf
from sklearn.metrics import classification_report

# -----------------------
# Load Data
# -----------------------
df = pd.read_csv("/content/New_CEFR_label.csv")

# Encode labels
le = LabelEncoder()
df["label"] = le.fit_transform(df["CEFR"])
num_classes = len(le.classes_)

# Train/test split (stratify to maintain class distribution)
X_train, X_test, y_train, y_test = train_test_split(
    df["Text"], df["label"], test_size=0.2, random_state=42, stratify=df["label"]
)

# -----------------------
# Oversample minority classes
# -----------------------
ros = RandomOverSampler(random_state=42)
X_train_res, y_train_res = ros.fit_resample(np.array(X_train).reshape(-1,1), y_train)
X_train_res = X_train_res.ravel()

# -----------------------
# Tokenization
# -----------------------
max_words = 30000
max_len = 400
tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(X_train_res)

X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train_res), maxlen=max_len)
X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_len)

# One-hot encode labels
y_train_cat = to_categorical(y_train_res, num_classes=num_classes)
y_test_cat = to_categorical(y_test, num_classes=num_classes)

# -----------------------
# Class weights
# -----------------------
class_weights = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y_train_res),
    y=y_train_res
)
class_weights_dict = dict(enumerate(class_weights))

# -----------------------
# Focal loss
# -----------------------
def focal_loss(gamma=2., alpha=.25):
    def loss_fn(y_true, y_pred):
        y_true = tf.cast(y_true, tf.float32)
        ce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)
        pt = tf.exp(-ce)
        return alpha * tf.pow(1-pt, gamma) * ce
    return loss_fn

# -----------------------
# Build Model
# -----------------------
model = Sequential([
    Embedding(max_words, 300),
    Bidirectional(LSTM(64, return_sequences=True)),  # smaller LSTM to reduce overfitting
    GlobalMaxPooling1D(),
    BatchNormalization(),
    Dropout(0.5),
    Dense(64, activation="relu"),
    Dropout(0.4),
    Dense(num_classes, activation="softmax")
])

# Compile
model.compile(
    loss=focal_loss(gamma=2., alpha=0.25),
    optimizer="adam",
    metrics=["accuracy", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]
)

# -----------------------
# Callbacks
# -----------------------
callbacks = [
    EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True),
    ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=3)
]
# -----------------------
# Train
# -----------------------
history = model.fit(
    X_train_seq, y_train_cat,
    validation_data=(X_test_seq, y_test_cat),
    epochs=20,
    batch_size=8,
    callbacks=callbacks,
    class_weight=class_weights_dict,
    verbose=1
)

# -----------------------
# Evaluation
# -----------------------
y_pred = model.predict(X_test_seq)
y_pred_classes = np.argmax(y_pred, axis=1)

print("Classification Report:\n")
print(classification_report(y_test, y_pred_classes, target_names=le.classes_))

# Overall metrics
loss, acc, precision, recall = model.evaluate(X_test_seq, y_test_cat, verbose=0)
f1 = 2 * (precision * recall) / (precision + recall + 1e-8)

print(f"Validation Accuracy: {acc:.4f}")
print(f"Validation Precision: {precision:.4f}")
print(f"Validation Recall: {recall:.4f}")
print(f"Validation F1-Score: {f1:.4f}")

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import class_weight
from imblearn.over_sampling import RandomOverSampler
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, GlobalMaxPooling1D, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.utils import to_categorical
import tensorflow as tf
from sklearn.metrics import classification_report

# -----------------------
# Load Data
# -----------------------
df = pd.read_csv("/content/New_CEFR_label.csv")

# Encode labels
le = LabelEncoder()
df["label"] = le.fit_transform(df["CEFR"])
num_classes = len(le.classes_)

# -----------------------
# Train/Validation/Test Split (70:15:15)
# -----------------------
X_temp, X_test, y_temp, y_test = train_test_split(
    df["Text"], df["label"], test_size=0.15, random_state=42, stratify=df["label"]
)

X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp, test_size=0.1765, random_state=42, stratify=y_temp
)
# 0.1765 * 0.85 ≈ 0.15, so final split ≈ 70:15:15

# -----------------------
# Oversample minority classes in training set
# -----------------------
ros = RandomOverSampler(random_state=42)
X_train_res, y_train_res = ros.fit_resample(np.array(X_train).reshape(-1,1), y_train)
X_train_res = X_train_res.ravel()

# -----------------------
# Tokenization
# -----------------------
max_words = 30000
max_len = 400
tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(X_train_res)

X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train_res), maxlen=max_len)
X_val_seq = pad_sequences(tokenizer.texts_to_sequences(X_val), maxlen=max_len)
X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_len)

# One-hot encode labels
y_train_cat = to_categorical(y_train_res, num_classes=num_classes)
y_val_cat = to_categorical(y_val, num_classes=num_classes)
y_test_cat = to_categorical(y_test, num_classes=num_classes)

# -----------------------
# Class weights
# -----------------------
class_weights = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y_train_res),
    y=y_train_res
)
class_weights_dict = dict(enumerate(class_weights))

# -----------------------
# Focal loss
# -----------------------
def focal_loss(gamma=2., alpha=.25):
    def loss_fn(y_true, y_pred):
        y_true = tf.cast(y_true, tf.float32)
        ce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)
        pt = tf.exp(-ce)
        return alpha * tf.pow(1-pt, gamma) * ce
    return loss_fn

# -----------------------
# Build Model
# -----------------------
model = Sequential([
    Embedding(max_words, 300),
    Bidirectional(LSTM(64, return_sequences=True)),
    GlobalMaxPooling1D(),
    BatchNormalization(),
    Dropout(0.5),
    Dense(64, activation="relu"),
    Dropout(0.4),
    Dense(num_classes, activation="softmax")
])

# Compile
model.compile(
    loss=focal_loss(gamma=2., alpha=0.25),
    optimizer="adam",
    metrics=["accuracy", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]
)

# -----------------------
# Callbacks
# -----------------------
callbacks = [
    EarlyStopping(monitor="val_loss", patience=3, restore_best_weights=True),
    ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=2),
    ModelCheckpoint("best_model.h5", monitor="val_accuracy", save_best_only=True, verbose=1)
]

# -----------------------
# Train
# -----------------------
history = model.fit(
    X_train_seq, y_train_cat,
    validation_data=(X_val_seq, y_val_cat),
    epochs=20,
    batch_size=8,
    callbacks=callbacks,
    class_weight=class_weights_dict,
    verbose=1
)

# -----------------------
# Load Best Model
# -----------------------
best_model = tf.keras.models.load_model("best_model.h5", custom_objects={'loss_fn': focal_loss()})

# -----------------------
# Evaluate on Test Set
# -----------------------
y_pred = best_model.predict(X_test_seq)
y_pred_classes = np.argmax(y_pred, axis=1)

print("Classification Report on Test Data:\n")
print(classification_report(y_test, y_pred_classes, target_names=le.classes_))

# Overall metrics
loss, acc, precision, recall = best_model.evaluate(X_test_seq, y_test_cat, verbose=0)
f1 = 2 * (precision * recall) / (precision + recall + 1e-8)

print(f"Test Accuracy: {acc:.4f}")
print(f"Test Precision: {precision:.4f}")
print(f"Test Recall: {recall:.4f}")
print(f"Test F1-Score: {f1:.4f}")

# -----------------------
# Save final model
# -----------------------
best_model.save("biLSTM_final_model.h5")
print("Final model saved as biLSTM_final_model.h5")

### LSTM ARCHITECTURE
# !pip install torch
# !pip install transformers
# !pip install scikit-learn
# !pip install datasets
# !pip install pandas
# !pip install tqdm
# !pip install numpy==1.26.4
# !pip install --upgrade datasets


# Install necessary libraries in a Colab/Jupyter cell if needed:
# !pip install torch transformers scikit-learn datasets pandas tqdm imbalanced-learn

import torch
from torch.utils.data import DataLoader
from torch.optim import AdamW
from transformers import BertTokenizer, BertForSequenceClassification
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
from datasets import Dataset
import pandas as pd
from tqdm import tqdm
from imblearn.over_sampling import RandomOverSampler

# Check device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'✅ Using device: {device}')

# Load dataset
df = pd.read_csv('/content/New_CEFR_label.csv')

# Label mapping — 8 emotion labels
label_map = {
    'A1': 0,
    'A2': 1,
    'B1': 2,
    'B2': 3,
    'C1':4,
    'C2':5,


}

# Map 'label' column to numeric IDs
df['label_id'] = df['CEFR'].str.strip().map(label_map)

# Drop unknown/invalid labels
df = df.dropna(subset=['label_id'])

# Convert label to int
df['label_id'] = df['label_id'].astype(int)

# Check distribution before oversampling
print("\n📊 Label distribution before oversampling:")
print(df['label_id'].value_counts())

# Apply RandomOverSampler
ros = RandomOverSampler(random_state=42)
# X_resampled, y_resampled = ros.fit_resample(df[['transcript']], df['label_id'])
X_resampled, y_resampled = ros.fit_resample(df[['Text']], df['label_id'])
# Create balanced DataFrame
resampled_df = pd.DataFrame({'Text': X_resampled['Text'], 'label_id': y_resampled})

# Check distribution after oversampling
print("\n📊 Label distribution after oversampling:")
print(resampled_df['label_id'].value_counts())

# Split data into train and validation
train_texts,test_texts val_texts, train_labels, val_labels = train_test_split(
    resampled_df['Text'].tolist(), resampled_df['label_id'].tolist(),
    test_size=0.2, random_state=42
)

# Load BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Tokenization function
def tokenize_function(examples):
    return tokenizer(examples["Text"], padding="max_length", truncation=True, max_length=128)

# Convert to Huggingface Dataset
train_dataset = Dataset.from_dict({"Text": train_texts, "label": train_labels})
val_dataset = Dataset.from_dict({"Text": val_texts, "label": val_labels})

# Tokenize datasets
train_dataset = train_dataset.map(tokenize_function, batched=True)
val_dataset = val_dataset.map(tokenize_function, batched=True)

# Set format for PyTorch
train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])

# DataLoaders
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)

# Load BERT model for sequence classification with 8 labels (as per label_map)
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)
model.to(device)

# Optimizer
optimizer = AdamW(model.parameters(), lr=2e-5)

# Training loop
epochs = 5

for epoch in range(epochs):
    print(f"\n🚀 Epoch {epoch+1}/{epochs}")
    model.train()
    total_loss = 0

    progress_bar = tqdm(train_loader, desc=f"Training Epoch {epoch+1}")

    for batch in progress_bar:
        optimizer.zero_grad()

        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['label'].to(device)

        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss

        total_loss += loss.item()
        loss.backward()
        optimizer.step()

        progress_bar.set_postfix({"loss": loss.item()})

    avg_train_loss = total_loss / len(train_loader)
    print(f"📊 Average Training Loss: {avg_train_loss:.4f}")

    # Validation phase
    model.eval()
    preds, true_labels = [], []

    with torch.no_grad():
        for batch in val_loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['label'].to(device)

            outputs = model(input_ids, attention_mask=attention_mask)
            logits = outputs.logits
            predictions = torch.argmax(logits, dim=-1)

            preds.extend(predictions.cpu().numpy())
            true_labels.extend(labels.cpu().numpy())

    acc = accuracy_score(true_labels, preds)
    print(f"✅ Validation Accuracy: {acc:.4f}")
    print(classification_report(true_labels, preds, digits=4))

print("\n✅ Training completed!")

# Save the model and tokenizer
model_dir = "./saved_CEFR"
model.save_pretrained(model_dir)
tokenizer.save_pretrained(model_dir)
print("✅ Model and tokenizer saved successfully!")



# 📦 Imports
from transformers import BertForSequenceClassification, BertTokenizer
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import torch

# Load model and tokenizer first ✅
model_dir = "./saved_CEFR"

loaded_model = BertForSequenceClassification.from_pretrained(model_dir)
loaded_tokenizer = BertTokenizer.from_pretrained(model_dir)

# Move model to device
loaded_model.to(device)
loaded_model.eval()

# Inverse label map for decoding predictions
inv_label_map = {v: k for k, v in label_map.items()}


print("\n📊 Computing Confusion Matrix...")

preds, true_labels = [], []

with torch.no_grad():
    for batch in val_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['label'].to(device)

        outputs = loaded_model(input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)

        preds.extend(predictions.cpu().numpy())
        true_labels.extend(labels.cpu().numpy())

# Compute confusion matrix
cm = confusion_matrix(true_labels, preds)

# Get labels in order
labels_order = [label for label in label_map.keys()]

# Plot using seaborn heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels_order, yticklabels=labels_order)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('📊 Confusion Matrix — text Classification')
plt.show()

from transformers import BertForSequenceClassification, BertTokenizer

# Directory to save the model
model_dir = "./saved_CEFR1"

# Save the model
model.save_pretrained(model_dir)

# Save the tokenizer
tokenizer.save_pretrained(model_dir)

print("✅ Model and tokenizer saved successfully!")

# 📦 Install required libraries (uncomment if needed)
# !pip install torch transformers scikit-learn datasets pandas tqdm imbalanced-learn

import torch
from torch.utils.data import DataLoader
from torch.optim import AdamW
from transformers import BertTokenizer, BertForSequenceClassification
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report
from datasets import Dataset
import pandas as pd
from tqdm import tqdm
from imblearn.over_sampling import RandomOverSampler
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# ✅ Device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'Using device: {device}')

# ✅ Load Dataset
df = pd.read_csv('/content/New_CEFR_label.csv')

# ✅ Label Mapping
label_map = {'A1': 0, 'A2': 1, 'B1': 2, 'B2': 3, 'C1': 4, 'C2': 5}
df['label_id'] = df['CEFR'].str.strip().map(label_map)
df = df.dropna(subset=['label_id'])
df['label_id'] = df['label_id'].astype(int)

# ✅ Oversample to handle class imbalance
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(df[['Text']], df['label_id'])
resampled_df = pd.DataFrame({'Text': X_resampled['Text'], 'label_id': y_resampled})

# ✅ Train/Validation Split
train_texts, val_texts, train_labels, val_labels = train_test_split(
    resampled_df['Text'].tolist(), resampled_df['label_id'].tolist(),
    test_size=0.2, random_state=42
)

# ✅ Tokenization
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

def tokenize_function(examples):
    return tokenizer(examples["Text"], padding="max_length", truncation=True, max_length=128)

train_dataset = Dataset.from_dict({"Text": train_texts, "label": train_labels})
val_dataset = Dataset.from_dict({"Text": val_texts, "label": val_labels})

train_dataset = train_dataset.map(tokenize_function, batched=True)
val_dataset = val_dataset.map(tokenize_function, batched=True)

train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])

train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=4)

# ✅ Load Model
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)
model.to(device)

optimizer = AdamW(model.parameters(), lr=2e-5)

# ✅ Training Loop
epochs = 5
for epoch in range(epochs):
    print(f"\n🚀 Epoch {epoch+1}/{epochs}")
    model.train()
    total_loss = 0
    train_preds, train_targets = [], []

    progress_bar = tqdm(train_loader, desc=f"Training Epoch {epoch+1}")
    for batch in progress_bar:
        optimizer.zero_grad()

        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['label'].to(device)

        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        logits = outputs.logits

        total_loss += loss.item()
        loss.backward()
        optimizer.step()

        predictions = torch.argmax(logits, dim=-1)
        train_preds.extend(predictions.cpu().numpy())
        train_targets.extend(labels.cpu().numpy())

        progress_bar.set_postfix({"loss": loss.item()})

    avg_train_loss = total_loss / len(train_loader)
    train_acc = accuracy_score(train_targets, train_preds)
    print(f"📊 Average Training Loss: {avg_train_loss:.4f} | Training Accuracy: {train_acc:.4f}")

    # ✅ Validation
    model.eval()
    val_preds, val_targets = [], []
    with torch.no_grad():
        for batch in val_loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['label'].to(device)

            outputs = model(input_ids, attention_mask=attention_mask)
            logits = outputs.logits
            predictions = torch.argmax(logits, dim=-1)

            val_preds.extend(predictions.cpu().numpy())
            val_targets.extend(labels.cpu().numpy())

    val_acc = accuracy_score(val_targets, val_preds)
    print(f"✅ Validation Accuracy: {val_acc:.4f}")
    print(classification_report(val_targets, val_preds, digits=4))

# ✅ Save model
model_dir = "./Transcript_model"
model.save_pretrained(model_dir)
tokenizer.save_pretrained(model_dir)
print("✅ Model and tokenizer saved.")

# ✅ Load test dataset
test_df = pd.read_csv('/content/New_CEFR_test.csv')  # Replace with your test file
test_df['label_id'] = test_df['CEFR'].str.strip().map(label_map)
test_df = test_df.dropna(subset=['label_id'])
test_df['label_id'] = test_df['label_id'].astype(int)

test_dataset = Dataset.from_dict({
    "Text": test_df["Text"].tolist(),
    "label": test_df["label_id"].tolist()
})

test_dataset = test_dataset.map(tokenize_function, batched=True)
test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
test_loader = DataLoader(test_dataset, batch_size=4)

# ✅ Evaluate on Test Set
model.eval()
test_preds, test_targets = [], []

with torch.no_grad():
    for batch in test_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['label'].to(device)

        outputs = model(input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)

        test_preds.extend(predictions.cpu().numpy())
        test_targets.extend(labels.cpu().numpy())

test_acc = accuracy_score(test_targets, test_preds)
test_precision = precision_score(test_targets, test_preds, average='weighted', zero_division=0)
test_recall = recall_score(test_targets, test_preds, average='weighted', zero_division=0)
test_f1 = f1_score(test_targets, test_preds, average='weighted', zero_division=0)

print(f"\n✅ Test Accuracy: {test_acc:.4f}")
print(f"🎯 Test Precision: {test_precision:.4f}")
print(f"🎯 Test Recall: {test_recall:.4f}")
print(f"🎯 Test F1 Score: {test_f1:.4f}")
print(classification_report(test_targets, test_preds, digits=4))

# ✅ Confusion Matrix
cm = confusion_matrix(test_targets, test_preds)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_map.keys(), yticklabels=label_map.keys())
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# ✅ Summary Report
summary = {
    "Model / Algorithm Used": "BERT (BertForSequenceClassification)",
    "Dataset Details": "CEFR text dataset with oversampling",
    "Labels": "A1, A2, B1, B2, C1, C2",
    "Learning Rate (Used Method)": "2e-5 (AdamW)",
    "Patience Count": "N/A",
    "Epochs": epochs,
    "Train Accuracy": f"{train_acc:.4f}",
    "Validation Accuracy": f"{val_acc:.4f}",
    "Test Accuracy": f"{test_acc:.4f}",
    "Test F1 -Score": f"{test_f1:.4f}",
    "Test Precision": f"{test_precision:.4f}",
    "Test Recall": f"{test_recall:.4f}",
    "Model Name": "Transcript_model"
}

print("\n📊 Model Summary:")
for key, val in summary.items():
    print(f"{key:30}: {val}")

### LSTM ARCHITECTURE
# !pip install torch
# !pip install transformers
# !pip install scikit-learn
# !pip install datasets
# !pip install pandas
# !pip install tqdm
# !pip install numpy==1.26.4
# !pip install --upgrade datasets


# Install necessary libraries in a Colab/Jupyter cell if needed:
# !pip install torch transformers scikit-learn datasets pandas tqdm imbalanced-learn

import torch
from torch.utils.data import DataLoader
from torch.optim import AdamW
from transformers import BertTokenizer, BertForSequenceClassification
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
from datasets import Dataset
import pandas as pd
from tqdm import tqdm
from imblearn.over_sampling import RandomOverSampler

# Check device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'✅ Using device: {device}')

# Load dataset
df = pd.read_csv('/content/data.csv')

# Label mapping — 8 emotion labels
label_map = {
    'A1': 0,
    'A2': 1,
    'B1': 2,
    'B2': 3,
    'C1':4,
    'C2':5,


}

# Map 'label' column to numeric IDs
df['label_id'] = df['CEFR'].str.strip().map(label_map)

# Drop unknown/invalid labels
df = df.dropna(subset=['label_id'])

# Convert label to int
df['label_id'] = df['label_id'].astype(int)

# Check distribution before oversampling
print("\n📊 Label distribution before oversampling:")
print(df['label_id'].value_counts())

# Apply RandomOverSampler
ros = RandomOverSampler(random_state=42)
# X_resampled, y_resampled = ros.fit_resample(df[['transcript']], df['label_id'])
X_resampled, y_resampled = ros.fit_resample(df[['transcript']], df['label_id'])
# Create balanced DataFrame
resampled_df = pd.DataFrame({'transcript': X_resampled['transcript'], 'label_id': y_resampled})

# Check distribution after oversampling
print("\n📊 Label distribution after oversampling:")
print(resampled_df['label_id'].value_counts())

# Split data into train and validation
train_texts, val_texts, train_labels, val_labels = train_test_split(
    resampled_df['transcript'].tolist(), resampled_df['label_id'].tolist(),
    test_size=0.2, random_state=42
)

# Load BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Tokenization function
def tokenize_function(examples):
    return tokenizer(examples["transcript"], padding="max_length", truncation=True, max_length=128)

# Convert to Huggingface Dataset
train_dataset = Dataset.from_dict({"transcript": train_texts, "label": train_labels})
val_dataset = Dataset.from_dict({"transcript": val_texts, "label": val_labels})

# Tokenize datasets
train_dataset = train_dataset.map(tokenize_function, batched=True)
val_dataset = val_dataset.map(tokenize_function, batched=True)

# Set format for PyTorch
train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])

# DataLoaders
train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=4)

# Load BERT model for sequence classification with 8 labels (as per label_map)
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)
model.to(device)

# Optimizer
optimizer = AdamW(model.parameters(), lr=2e-5)

# Training loop
epochs = 10

for epoch in range(epochs):
    print(f"\n🚀 Epoch {epoch+1}/{epochs}")
    model.train()
    total_loss = 0
    train_preds, train_labels = [], []

    progress_bar = tqdm(train_loader, desc=f"Training Epoch {epoch+1}")

    for batch in progress_bar:
        optimizer.zero_grad()

        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['label'].to(device)

        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        logits = outputs.logits

        total_loss += loss.item()
        loss.backward()
        optimizer.step()

        # Collect predictions for training accuracy
        predictions = torch.argmax(logits, dim=-1)
        train_preds.extend(predictions.cpu().numpy())
        train_labels.extend(labels.cpu().numpy())

        progress_bar.set_postfix({"loss": loss.item()})

    avg_train_loss = total_loss / len(train_loader)
    train_acc = accuracy_score(train_labels, train_preds)
    print(f"📊 Average Training Loss: {avg_train_loss:.4f} | Training Accuracy: {train_acc:.4f}")

# for epoch in range(epochs):
#     print(f"\n🚀 Epoch {epoch+1}/{epochs}")
#     model.train()
#     total_loss = 0

#     progress_bar = tqdm(train_loader, desc=f"Training Epoch {epoch+1}")

#     for batch in progress_bar:
#         optimizer.zero_grad()

#         input_ids = batch['input_ids'].to(device)
#         attention_mask = batch['attention_mask'].to(device)
#         labels = batch['label'].to(device)

#         outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
#         loss = outputs.loss

#         total_loss += loss.item()
#         loss.backward()
#         optimizer.step()

#         progress_bar.set_postfix({"loss": loss.item()})

#     avg_train_loss = total_loss / len(train_loader)
#     print(f"📊 Average Training Loss: {avg_train_loss:.4f}")

    # Validation phase
    model.eval()
    preds, true_labels = [], []

    with torch.no_grad():
        for batch in val_loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['label'].to(device)

            outputs = model(input_ids, attention_mask=attention_mask)
            logits = outputs.logits
            predictions = torch.argmax(logits, dim=-1)

            preds.extend(predictions.cpu().numpy())
            true_labels.extend(labels.cpu().numpy())

    acc = accuracy_score(true_labels, preds)
    print(f"✅ Validation Accuracy: {acc:.4f}")
    print(classification_report(true_labels, preds, digits=4))

print("\n✅ Training completed!")

# Save the model and tokenizer
model_dir = "./saved_Model"
model.save_pretrained(model_dir)
tokenizer.save_pretrained(model_dir)
print("✅ Model and tokenizer saved successfully!")



# 📦 Imports
from transformers import BertForSequenceClassification, BertTokenizer
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import torch

# Load model and tokenizer first ✅
model_dir = "./saved_Model"

loaded_model = BertForSequenceClassification.from_pretrained(model_dir)
loaded_tokenizer = BertTokenizer.from_pretrained(model_dir)

# Move model to device
loaded_model.to(device)
loaded_model.eval()

# Inverse label map for decoding predictions
inv_label_map = {v: k for k, v in label_map.items()}


print("\n📊 Computing Confusion Matrix...")

preds, true_labels = [], []

with torch.no_grad():
    for batch in val_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['label'].to(device)

        outputs = loaded_model(input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        predictions = torch.argmax(logits, dim=-1)

        preds.extend(predictions.cpu().numpy())
        true_labels.extend(labels.cpu().numpy())

# Compute confusion matrix
cm = confusion_matrix(true_labels, preds)

# Get labels in order
labels_order = [label for label in label_map.keys()]

# Plot using seaborn heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels_order, yticklabels=labels_order)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('📊 Confusion Matrix — text Classification')
plt.show()

## evaluvate the model ####
import torch
from transformers import BertTokenizer, BertForSequenceClassification

# Load saved model + tokenizer
model_dir = "/content/save_model"
model = BertForSequenceClassification.from_pretrained(model_dir)
tokenizer = BertTokenizer.from_pretrained(model_dir)

# Move to device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

# Label map (same as training)
label_map = {
    'A1': 0,
    'A2': 1,
    'B1': 2,
    'B2': 3,
    'C1': 4,
    'C2': 5
}
inv_label_map = {v: k for k, v in label_map.items()}

# 🔮 Prediction function
def predict_cefr(text):
    # Tokenize input
    inputs = tokenizer(text, return_tensors="pt", padding=True, truncation=True, max_length=128)
    inputs = {key: val.to(device) for key, val in inputs.items()}

    # Run model
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        predicted_class_id = torch.argmax(logits, dim=-1).item()

    return inv_label_map[predicted_class_id]

# 👉 Example usage
sample_text = "Member, when I was working in a grammar pharma industry, Then there was a customer where we had to make deal with them, but he was not he was not his complaint was that with the regarding our regarding our product. So  we we Mumbai's Lee I I I called her. I talked to her talked to her, and asked about what what her complaint is. Then after hearing after hearing her complaint, I tried to resolve it. So what complaint was regarding us our product. So we we particularly particularly particularly knew what what her complaint with our product denied. Then then we made changes in our product, and after after doing after doing changes in our product, I made I made her sure that this will not happen again. That's how we we take on the situation."
predicted_label = predict_cefr(sample_text)
print(f"✅ Predicted CEFR level: {predicted_label}")

# 📦 Imports
import torch
from torch.utils.data import DataLoader
from torch.optim import AdamW
from transformers import BertTokenizer, BertForSequenceClassification
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from datasets import Dataset
import pandas as pd
from tqdm import tqdm
from imblearn.over_sampling import RandomOverSampler
import matplotlib.pyplot as plt
import seaborn as sns

# ✅ Check device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'✅ Using device: {device}')

# 📂 Load dataset
df = pd.read_csv('/content/New_CEFR_label.csv')

# 🔖 Label mapping
label_map = {
    'A1': 0, 'A2': 1, 'B1': 2,
    'B2': 3, 'C1': 4, 'C2': 5
}

df['label_id'] = df['CEFR'].str.strip().map(label_map)
df = df.dropna(subset=['label_id'])
df['label_id'] = df['label_id'].astype(int)

print("\n📊 Label distribution before oversampling:")
print(df['label_id'].value_counts())

# ⚖️ Oversample to balance classes
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(df[['Text']], df['label_id'])
resampled_df = pd.DataFrame({'Text': X_resampled['Text'], 'label_id': y_resampled})

print("\n📊 Label distribution after oversampling:")
print(resampled_df['label_id'].value_counts())

# ✂️ Split into train / val / test (70:15:15)
train_texts, temp_texts, train_labels, temp_labels = train_test_split(
    resampled_df['Text'].tolist(),
    resampled_df['label_id'].tolist(),
    test_size=0.30,  # 30% goes to val+test
    random_state=42
)

val_texts, test_texts, val_labels, test_labels = train_test_split(
    temp_texts, temp_labels,
    test_size=0.50,   # split 30% into 15% val + 15% test
    random_state=42
)

print(f"📂 Train: {len(train_texts)} ({len(train_texts)/len(resampled_df):.2%})")
print(f"📂 Val:   {len(val_texts)} ({len(val_texts)/len(resampled_df):.2%})")
print(f"📂 Test:  {len(test_texts)} ({len(test_texts)/len(resampled_df):.2%})")

# 📝 Tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

def tokenize_function(examples):
    return tokenizer(examples["Text"], padding="max_length", truncation=True, max_length=128)

# 📚 HuggingFace Datasets
train_dataset = Dataset.from_dict({"Text": train_texts, "label": train_labels}).map(tokenize_function, batched=True)
val_dataset   = Dataset.from_dict({"Text": val_texts, "label": val_labels}).map(tokenize_function, batched=True)
test_dataset  = Dataset.from_dict({"Text": test_texts, "label": test_labels}).map(tokenize_function, batched=True)

# ⚙️ Format for PyTorch
for dataset in [train_dataset, val_dataset, test_dataset]:
    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])

# 🔄 DataLoaders
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader   = DataLoader(val_dataset, batch_size=16)
test_loader  = DataLoader(test_dataset, batch_size=16)

# 🤖 Model
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)
model.to(device)

optimizer = AdamW(model.parameters(), lr=2e-5)
epochs = 5

# 📊 Tracking losses & accuracy
train_losses, val_losses = [], []
train_accuracies, val_accuracies = [], []

for epoch in range(epochs):
    print(f"\n🚀 Epoch {epoch+1}/{epochs}")
    model.train()
    total_loss, correct, total = 0, 0, 0

    progress_bar = tqdm(train_loader, desc=f"Training Epoch {epoch+1}")
    for batch in progress_bar:
        optimizer.zero_grad()

        input_ids, attention_mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        logits = outputs.logits

        total_loss += loss.item()
        loss.backward()
        optimizer.step()

        preds = torch.argmax(logits, dim=-1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

        progress_bar.set_postfix({"loss": loss.item()})

    avg_train_loss = total_loss / len(train_loader)
    train_acc = correct / total
    train_losses.append(avg_train_loss)
    train_accuracies.append(train_acc)

    # 🔎 Validation
    model.eval()
    val_loss, val_correct, val_total = 0, 0, 0
    preds, true_labels = [], []

    with torch.no_grad():
        for batch in val_loader:
            input_ids, attention_mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)
            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
            val_loss += outputs.loss.item()

            logits = outputs.logits
            predictions = torch.argmax(logits, dim=-1)
            preds.extend(predictions.cpu().numpy())
            true_labels.extend(labels.cpu().numpy())

            val_correct += (predictions == labels).sum().item()
            val_total += labels.size(0)

    avg_val_loss = val_loss / len(val_loader)
    val_acc = val_correct / val_total
    val_losses.append(avg_val_loss)
    val_accuracies.append(val_acc)

    print(f"📊 Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f}")
    print(f"✅ Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}")

# 📈 Plot training curves
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(train_losses, label="Train Loss")
plt.plot(val_losses, label="Val Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.title("📉 Training & Validation Loss")

plt.subplot(1,2,2)
plt.plot(train_accuracies, label="Train Accuracy")
plt.plot(val_accuracies, label="Val Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.title("📈 Training & Validation Accuracy")
plt.show()

# 🧪 Final Evaluation on Test Set
model.eval()
test_preds, test_true = [], []
with torch.no_grad():
    for batch in test_loader:
        input_ids, attention_mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['label'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask)
        predictions = torch.argmax(outputs.logits, dim=-1)

        test_preds.extend(predictions.cpu().numpy())
        test_true.extend(labels.cpu().numpy())

test_acc = accuracy_score(test_true, test_preds)
print(f"\n🧪 Test Accuracy: {test_acc:.4f}")
print(classification_report(test_true, test_preds, target_names=label_map.keys()))

# 🔎 Confusion Matrices
def plot_confusion_matrix(y_true, y_pred, title):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(7,6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=label_map.keys(),
                yticklabels=label_map.keys())
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title(title)
    plt.show()

# Validation confusion matrix
plot_confusion_matrix(true_labels, preds, "📊 Confusion Matrix — Validation")

# Test confusion matrix
plot_confusion_matrix(test_true, test_preds, "📊 Confusion Matrix — Test")